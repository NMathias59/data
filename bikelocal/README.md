# Local Bike Data Warehouse

Un entrepÃ´t de donnÃ©es moderne pour l'analyse des ventes et performances de Local Bike, construit avec dbt et ClickHouse.

## ğŸ—ï¸ Architecture

Ce projet dbt suit une architecture en couches pour une transformation de donnÃ©es robuste et maintenable :

```
ğŸ“ bikelocal/
â”œâ”€â”€ ğŸ“ models/
â”‚   â”œâ”€â”€ ğŸ“ staging/           # DonnÃ©es brutes nettoyÃ©es
â”‚   â”œâ”€â”€ ğŸ“ intermediate/      # MÃ©triques business agrÃ©gÃ©es
â”‚   â””â”€â”€ ğŸ“ marts/            # Tables de reporting finales
â”œâ”€â”€ ğŸ“ seeds/                # DonnÃ©es de rÃ©fÃ©rence statiques
â”œâ”€â”€ ğŸ“ tests/                # Tests de qualitÃ© des donnÃ©es
â””â”€â”€ ğŸ“ macros/               # Fonctions SQL rÃ©utilisables
```

### Couches de Transformation

#### 1. Staging Layer (9 modÃ¨les)
Nettoyage et standardisation des donnÃ©es brutes :
- **Sources** : CSV clients, produits, commandes, stocks
- **MatÃ©rialisation** : `view`
- **ResponsabilitÃ©s** : Types de donnÃ©es, noms de colonnes, filtres de qualitÃ©

#### 2. Intermediate Layer (11 modÃ¨les)
Calculs de mÃ©triques business complexes :
- **AgrÃ©gations** : Revenus, quantitÃ©s, moyennes par entitÃ©
- **Jointures** : Enrichissement avec donnÃ©es contextuelles
- **MatÃ©rialisation** : `incremental` (materialized MergeTree tables dans ClickHouse, modÃ¨les prÃ©fixÃ©s `int_` â€” ex : `int_sales__category_revenue`). Ces modÃ¨les nÃ©cessitent un **`unique_key`** explicite (souvent composite, ex. `category_id, store_id, year_month`) pour un incrÃ©mental fiable.

#### 3. Marts Layer (14 modÃ¨les)
Tables optimisÃ©es pour l'analyse et le reporting :
- **Dimensions** : Clients, produits, magasins, employÃ©s, temps
- **Faits** : Ventes, inventaire, performances opÃ©rationnelles
- **MatÃ©rialisation** : `table`

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
- Python 3.8+
- dbt 1.11.2
- ClickHouse 25.10+

### Installation
```bash
# Cloner le repository
git clone <repository-url>
cd bikelocal

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer l'environnement dbt
cp profiles.yml.example ~/.dbt/profiles.yml
# Ã‰diter profiles.yml avec vos credentials ClickHouse
```

### ExÃ©cution
```powershell
# Activer l'environnement virtuel (Windows PowerShell)
. .\.venv_dbt\Scripts\Activate.ps1

# ExÃ©cuter tous les modÃ¨les + tests (recommandÃ©)
dbt build

# Ou exÃ©cuter uniquement les modÃ¨les
dbt run

# Tester la qualitÃ© des donnÃ©es (si vous n'avez pas utilisÃ© dbt build)
dbt test

# GÃ©nÃ©rer la documentation
dbt docs generate

# DÃ©marrer le serveur de docs (par dÃ©faut port 8080). Si 8080 est indisponible, utilisez 8081 :
dbt docs serve --port 8080
# ou
dbt docs serve --port 8081
```

## ğŸ“Œ DÃ©couverte & Gouvernance

- **Tags** : les rapports sont taguÃ©s `rpt` (ex: `tags: ['rpt']`) â€” permet de filtrer rapidement avec `dbt ls --select tag:rpt`.
- **Exposures** : les rapports `rpt_*` sont exposÃ©s via `models/exposures.yml` et lient chaque rapport Ã  un dashboard Power BI et Ã  un owner pour traÃ§abilitÃ©.
- **CI** : un workflow GitHub Actions (`.github/workflows/dbt-ci.yml`) exÃ©cute `dbt build` et `dbt docs generate` sur PR pour prÃ©venir les rÃ©gressions.
- **Recommendation incremental** : certains rapports volumineux incluent `meta.incremental_recommendation: true` dans la documentation pour indiquer qu'une matÃ©rialisation `incremental` peut Ãªtre envisagÃ©e.

### ğŸš€ OpÃ©rations - Mode incremental

**Note** : Depuis la migration vers ClickHouse, de nombreux modÃ¨les intermÃ©diaires (`int_*`) sont matÃ©rialisÃ©s en `incremental` (MergeTree) dans la base `localbike_raw_intermediate`. Les marts consomment ces `int_*` pour fiabilitÃ© et performance (extraction optimisÃ©e, Ã©vite les limites SQL de ClickHouse). Les `int_*` exigent un `unique_key` explicite â€” souvent composite (ex. `category_id, store_id, year_month`).

- **Append-only** : Les rapports temporels (`rpt_*`) sont configurÃ©s en mode `incremental` pour n'ajouter que des pÃ©riodes nouvelles (par `year_month`). Les calculs historiques ne sont pas modifiÃ©s automatiquement â€” pour corriger ou backfiller des pÃ©riodes antÃ©rieures, exÃ©cutez un `dbt run --select <model> --full-refresh` ciblÃ©.
- **Snapshots & updates** : Pour des rapports de snapshot (ex. inventaire, LTV), l'incrÃ©mental insÃ¨re de nouveaux Ã©lÃ©ments (nouvelles customers, nouvelles combinaisons store/product). Les mises Ã  jour d'un enregistrement existant nÃ©cessitent un `--full-refresh` sur le modÃ¨le concernÃ© ou l'utilisation d'une stratÃ©gie de merge/replace en production.
- **Bonnes pratiques** : Planifier des jobs de backfill (p.ex. quotidien pour la pÃ©riode courante ou hebdomadaire pour les 2 derniers mois) pour prendre en charge les arrivÃ©es tardives et garantir la complÃ©tude des KPIs.

## ğŸ“Š ModÃ¨les Disponibles

### Dimensions (Tables de rÃ©fÃ©rence)
- `dim_customers` : Profils clients avec segmentation RFM
- `dim_products` : Catalogue produits avec catÃ©gories et marques
- `dim_staff` : Ã‰quipe avec hiÃ©rarchie managÃ©riale
- `dim_stores` : Magasins avec informations gÃ©ographiques
- `dim_time` : Dimensions temporelles pour analyses

### Faits (MÃ©triques business)
- `fct_sales` : Transactions de vente dÃ©taillÃ©es
- `fct_inventory` : Niveaux de stock par produit/magasin
- `fct_operations_performance` : MÃ©triques de fulfillment et qualitÃ© de service
- `fct_product_profitability` : RentabilitÃ© par produit
- `fct_staff_performance` : Performance des ventes par employÃ©

### Rapports (AgrÃ©gats pour BI)
- `rpt_sales_summary` : Vue d'ensemble des ventes
- `rpt_customer_ltv` : Valeur vie client
- `rpt_inventory_status` : Ã‰tat des stocks

### KPI & descriptions des tables (Dimensions / Faits / Rapports)
Cette section dÃ©crit rapidement les KPI principaux exposÃ©s par chaque table â€” utile pour les auteurs Power BI et la validation mÃ©tier.

#### Dimensions
- `dim_customers` : KPIs clÃ©s â€” **lifetime_value**, `rfm_segment`, `total_orders`, `avg_order_value`, `days_since_last_order`.
- `dim_products` : KPIs clÃ©s â€” `list_price`, `price_tier`, `estimated_cost_price`, `estimated_margin`, `product_category_group`.
- `dim_staff` : KPIs clÃ©s â€” `total_orders_processed`, `total_items_sold`, `total_sales_revenue`, `performance_tier`.
- `dim_stores` : KPIs / attributs â€” `region`, `store_type`, `store_name`, `city`, `state` (utiles pour segmentation et gÃ©ographie).
- `dim_time` : ClÃ©s temporelles â€” `date_key`, `year`, `month`, `year_month`, `quarter` (utilisÃ©es pour toutes les agrÃ©gations temporelles).

#### Faits (exemples de KPIs exposÃ©s)
- `fct_sales` : **net_revenue**, `gross_revenue`, `total_discounts`, `total_items_sold`, `unique_customers`, `avg_order_value`, `revenue_by_period`.
- `fct_inventory` : `total_stock_quantity`, `avg_stock_per_store`, `months_of_stock_coverage`, `stock_turnover_rate`, `stock_optimization_status`.
- `fct_operations_performance` : SLA/KPIs â€” `on_time_rate`, `days_to_ship`, `orders_processed`, `revenue_per_order`, `fulfillment_status`.
- `fct_product_profitability` : `estimated_cost_price`, `estimated_margin`, `profit_margin_percentage`, `estimated_profit`, `revenue_impact`.
- `fct_staff_performance` : `total_sales_revenue`, `avg_order_value`, `revenue_rank_in_store`, `performance_tier`.
- `fct_category_performance` : `total_revenue`, `products_in_category`, `contribution_pct`, `category_ranking`.

#### Rapports (agrÃ©gats / KPI prÃªts Ã  l'emploi)
- `rpt_sales_summary` : KPIs â€” `total_revenue`, `total_orders`, `revenue_growth_pct`, `top_categories`, `revenue_by_store`.
- `rpt_customer_ltv` : KPIs â€” `customer_id`, `lifetime_value`, `avg_order_value`, `ltv_segment`, `churn_risk`.
- `rpt_inventory_status` : KPIs â€” `product_id`, `total_stock_quantity`, `stores_with_stock`, `low_stock_flag`, `recommended_reorder_qty`.
- `rpt_category_growth_analysis` : KPIs â€” `year_month`, **`revenue_12m_rolling_avg`**, `revenue_ytd`, `revenue_growth_pct`, `growth_contribution_12m_pct`, `price_tier`.

> ğŸ’¡ Astuce : les `rpt_*` sont conÃ§us pour Ãªtre consommÃ©s directement par des outils BI (Power BI) â€” ils contiennent des KPIs prÃªts Ã  l'emploi et des clÃ©s de jointure vers les dimensions.

## ğŸ› ï¸ Technologies

- **dbt** 1.11.2 : Orchestration des transformations
- **ClickHouse** 25.10+ : Base de donnÃ©es analytique haute performance
- **SQL** : Langage de transformation avec extensions ClickHouse
- **YAML** : Configuration et mÃ©tadonnÃ©es

### ParticularitÃ©s ClickHouse
- MatÃ©rialiser les intermÃ©diaires (`int_*`) en `MergeTree` permet de contourner des limitations (correlated subqueries, nested aggregates) et d'amÃ©liorer les performances.
- Ã‰viter les agrÃ©gations imbriquÃ©es : utilisez des CTE / sous-requÃªtes groupÃ©es ou materialize des Ã©tapes intermÃ©diaires.
- Utiliser des alias explicites pour les colonnes (`AS ...`) â€” cela Ã©vite des erreurs d'identifiant et facilite la validation dbt.
- S'assurer que l'utilisateur ClickHouse a les privilÃ¨ges nÃ©cessaires (CREATE, INSERT, SELECT) sur les bases : `localbike_raw`, `localbike_raw_staging`, `localbike_raw_intermediate`, `localbike_raw_marts`.

## ğŸ“ˆ Utilisation avec Power BI

Les tables marts sont optimisÃ©es pour la modÃ©lisation constellation Power BI :

1. **Connexion** : Utiliser le connecteur ClickHouse Power BI
2. **Dimensions** : Tables `dim_*` comme tables de recherche
3. **Faits** : Tables `fct_*` comme mesures et KPIs
4. **Rapports** : Tables `rpt_*` pour tableaux de bord prÃ©-calculÃ©s

### SchÃ©ma RecommandÃ©
```
dim_customers â”€â”€â”
dim_products  â”€â”€â”¼â”€ fct_sales â”€â”€ rpt_sales_summary
dim_staff     â”€â”€â”˜
dim_stores      â”‚
dim_time      â”€â”€â”˜
```

## ğŸ”§ DÃ©veloppement

### Structure des Branches
- `main` : Code de production
- `develop` : DÃ©veloppement actif
- `feature/*` : Nouvelles fonctionnalitÃ©s

### Tests
> Note : le test d'unicitÃ© pour `int_sales__category_revenue` a Ã©tÃ© mis Ã  jour pour vÃ©rifier l'unicitÃ© sur **(category_id, store_id, year_month)** â€” il reflÃ¨te dÃ©sormais la granularitÃ© mensuelle par magasin.

```bash
# Tests unitaires
dbt test

# Tests personnalisÃ©s
dbt run-operation custom_tests
```

### DÃ©ploiement
```bash
# Validation avant dÃ©ploiement
dbt run --dry-run

# DÃ©ploiement en production
dbt run --target prod
```

## ğŸ“š Ressources

- [Documentation dbt](https://docs.getdbt.com/docs/introduction)
- [Guide ClickHouse](https://clickhouse.com/docs/)
- [Power BI + ClickHouse](https://clickhouse.com/docs/en/integrations/powerbi)

## ğŸ¤ Contribution

1. CrÃ©er une branche `feature/nom-fonctionnalite`
2. Commiter avec messages descriptifs
3. Ouvrir une Pull Request vers `develop`
4. Validation par les tests automatiques

---

**Local Bike** - DonnÃ©es au service de la performance commerciale ğŸš´â€â™‚ï¸
